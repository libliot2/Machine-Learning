import pandas as pd
import numpy as np
import os
import sys
import time
from sklearn.model_selection import train_test_split
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import SMOTE
from collections import Counter

# ç¡®ä¿èƒ½å¯¼å…¥åŒç›®å½•ä¸‹çš„æ¨¡å—
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from model import train_algo_wrapper
from model_eval import evaluate_metrics

def run_comprehensive_experiment(
    data_path='../data/covtype_processed.csv',
    sample_limit=None  # ğŸ’¡ é™åˆ¶è®­ç»ƒæ ·æœ¬æ•°ä»¥åŠ é€Ÿå®éªŒ (è®¾ä¸º None åˆ™è·‘å…¨é‡)
):
    print("=" * 60)
    print(">>> ç»¼åˆå®éªŒï¼šå¤šæ¨¡å‹ vs. é‡é‡‡æ ·ç­–ç•¥ (Class Imbalance)")
    print("=" * 60)

    # 1. åŠ è½½æ•°æ®
    if not os.path.exists(data_path):
        print(f"[é”™è¯¯] æ‰¾ä¸åˆ°æ–‡ä»¶: {data_path}")
        return
    
    print(f"Loading Data: {data_path} ...")
    df = pd.read_csv(data_path)
    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values

    # 2. åˆ’åˆ†æ•°æ®é›† (ä¿æŒç»Ÿä¸€çš„æµ‹è¯•é›†)
    # stratify=y ç¡®ä¿æµ‹è¯•é›†å’Œè®­ç»ƒé›†çš„ç±»åˆ«åˆ†å¸ƒä¸åŸå§‹æ•°æ®ä¸€è‡´
    X_train_full, X_test, y_train_full, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )

    # ğŸ’¡ å¦‚æœå¼€å¯äº†é‡‡æ ·é™åˆ¶ï¼Œä»è®­ç»ƒé›†ä¸­å†æŠ½å–ä¸€éƒ¨åˆ†
    if sample_limit and sample_limit < len(X_train_full):
        print(f"\n[æ³¨æ„] ä¸ºäº†åŠ é€Ÿå®éªŒï¼Œä»…ä½¿ç”¨ {sample_limit} æ¡è®­ç»ƒæ ·æœ¬ã€‚")
        # å†æ¬¡åˆ†å±‚é‡‡æ ·
        sample_indices = np.random.choice(len(X_train_full), sample_limit, replace=False)
        # è¿™é‡Œçš„ç®€å•éšæœºæŠ½æ ·å¯èƒ½ä¼šç ´ååˆ†å¸ƒï¼Œä¸¥è°¨åšæ³•æ˜¯ç”¨ train_test_split å†åˆ‡ä¸€æ¬¡
        X_train_sub, _, y_train_sub, _ = train_test_split(
            X_train_full, y_train_full, train_size=sample_limit, random_state=42, stratify=y_train_full
        )
        X_train, y_train = X_train_sub, y_train_sub
    else:
        print(f"\n[æ³¨æ„] ä½¿ç”¨å…¨é‡è®­ç»ƒé›† ({len(X_train_full)} samples)ã€‚è¯·è€å¿ƒç­‰å¾…ã€‚")
        X_train, y_train = X_train_full, y_train_full

    # 3. å®šä¹‰å®éªŒé…ç½®
    models_to_test = ['LogisticRegression', 'DecisionTree', 'RandomForest']
    
    strategies = {
        'Baseline (Raw)': None,
        'UnderSampling': RandomUnderSampler(random_state=42),
        'OverSampling (SMOTE)': SMOTE(random_state=42)
    }

    results = []

    # 4. å¼€å§‹å¾ªç¯å®éªŒ
    for model_name in models_to_test:
        print(f"\n" + "-"*30)
        print(f"ğŸ¤– å½“å‰æ¨¡å‹: {model_name}")
        print("-"*30)

        for strategy_name, sampler in strategies.items():
            print(f"   > ç­–ç•¥: {strategy_name} ...", end=" ")
            start_time = time.time()

            # (A) é‡é‡‡æ · (ä»…é’ˆå¯¹å½“å‰è¿™ä¸€è½®çš„ X_train)
            X_res, y_res = X_train, y_train
            if sampler is not None:
                try:
                    X_res, y_res = sampler.fit_resample(X_train, y_train)
                except Exception as e:
                    print(f"[Skipped] Resampling failed: {e}")
                    continue
            
            # (B) è®­ç»ƒæ¨¡å‹
            # é‡æ–°åˆå§‹åŒ–æ¨¡å‹ï¼Œç¡®ä¿å¹²å‡€çš„çŠ¶æ€
            clf = train_algo_wrapper(model_name)
            clf.fit(X_res, y_res)

            # (C) é¢„æµ‹ (å¿…é¡»åœ¨åŸå§‹çº¯å‡€çš„ X_test ä¸Š)
            y_pred = clf.predict(X_test)
            
            # å°è¯•è·å–æ¦‚ç‡ç”¨äºè®¡ç®— AUC (å¦‚æœæ”¯æŒ)
            y_proba = None
            if hasattr(clf, "predict_proba"):
                try:
                    y_proba = clf.predict_proba(X_test)
                except:
                    pass
            
            # å¦‚æœæ²¡æœ‰æ¦‚ç‡ï¼Œç”¨é¢„æµ‹æ ‡ç­¾ä»£æ›¿ (AUC è®¡ç®—ä¼šä¸å‡†ï¼Œä½†ä¸ºäº†ä»£ç ä¸å´©)
            if y_proba is None:
                y_proba = y_pred

            # (D) è®¡ç®—æŒ‡æ ‡
            # æˆ‘ä»¬ç›´æ¥è°ƒç”¨ sklearn çš„å‡½æ•°è®¡ç®—éœ€è¦çš„ç‰¹å®šæŒ‡æ ‡ï¼Œæ¯”è°ƒç”¨ evaluate_metrics æ›´çµæ´»
            from sklearn.metrics import accuracy_score, f1_score, recall_score
            
            acc = accuracy_score(y_test, y_pred)
            # å…³æ³¨ Macro Average (å®å¹³å‡)ï¼Œè¿™å¯¹ä¸å¹³è¡¡ç±»åˆ«æœ€é‡è¦
            f1_macro = f1_score(y_test, y_pred, average='macro')
            recall_macro = recall_score(y_test, y_pred, average='macro')
            
            elapsed = time.time() - start_time
            print(f"å®Œæˆ ({elapsed:.1f}s) | Acc: {acc:.4f} | F1-Macro: {f1_macro:.4f}")

            results.append({
                'Model': model_name,
                'Strategy': strategy_name,
                'Accuracy': acc,
                'Macro F1': f1_macro,
                'Macro Recall': recall_macro,
                'Time(s)': elapsed
            })

    # 5. è¾“å‡ºæœ€ç»ˆå¯¹æ¯”è¡¨
    print("\n" + "="*80)
    print(f"{'Model':<20} | {'Strategy':<20} | {'Accuracy':<8} | {'Macro F1':<8} | {'Macro Rec':<8}")
    print("-" * 80)
    
    # å°†ç»“æœè½¬æ¢ä¸º DataFrame æ–¹ä¾¿å±•ç¤º (å¦‚æœè£…äº† pandas)
    res_df = pd.DataFrame(results)
    # æŒ‰æ¨¡å‹å’Œ F1 åˆ†æ•°æ’åº
    res_df = res_df.sort_values(by=['Model', 'Macro F1'], ascending=[True, False])
    
    for _, row in res_df.iterrows():
        print(f"{row['Model']:<20} | {row['Strategy']:<20} | {row['Accuracy']:.4f}   | {row['Macro F1']:.4f}   | {row['Macro Recall']:.4f}")
    
    print("="*80)
    
    # 6. ä¿å­˜ç»“æœåˆ° CSVï¼Œæ–¹ä¾¿å†™æŠ¥å‘Šç”¨
    res_df.to_csv('../images/experiment_resampling_results.csv', index=False)
    print("å®éªŒç»“æœå·²ä¿å­˜è‡³ ../images/experiment_resampling_results.csv")

if __name__ == "__main__":
    # å»ºè®®å…ˆç”¨ 50000 æ ·æœ¬è·‘é€šï¼Œç¡®è®¤æ— è¯¯åå†è®¾ä¸º None è·‘å…¨é‡
    run_comprehensive_experiment(sample_limit=None)